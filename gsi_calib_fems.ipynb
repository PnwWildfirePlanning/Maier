{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7ff09-0aae-49b4-bcf8-e5850e6ef9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v.20251106\n",
    "#b.maier\n",
    "#for calibrating gsi to fems field sample fuel moisture data\n",
    "#most of gsi calculation script lifted from matt jolly\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import matplotlib.dates as mdates\n",
    "import os.path\n",
    "from math import *\n",
    "import itertools\n",
    "#%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "proj_crs = 4326\n",
    "tz_local = 'US/Pacific'\n",
    "\n",
    "cwd = 'C:\\\\1_Projects\\\\NfdrsGsi\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663ac92-b089-4685-a1d9-228cf4617f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fems api urls\n",
    "url_fuelmodel = 'https://fems.fs2c.usda.gov/fuelmodel/apis/graphql'\n",
    "url_climatology = 'https://fems.fs2c.usda.gov/api/climatology/graphql'\n",
    "\n",
    "#func to return data from fems api\n",
    "def returnGraphQl(url, query, variables):\n",
    "\tr = requests.post(url, json={'query': query, 'variables': variables})\n",
    "\tr_json = json.loads(r.text)\n",
    "\treturn r_json\n",
    "\n",
    "#for making output dirs\n",
    "import os\n",
    "def make_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    else:\n",
    "        pass\n",
    "make_dir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b60a6-bef6-48b4-8ecd-d1a500cc26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return geojson from rest service\n",
    "#set to use pnw fdra, if using other fdra here fdra must have attributes ParentDocName and FDRAName... \n",
    "def geojson_rest(url):\n",
    "\treq = urllib.request.urlopen(url)\n",
    "\tgjson = req.read().decode('utf-8')\n",
    "\tgdf = gpd.read_file(gjson)\n",
    "\treturn gdf \n",
    "\n",
    "#get pnw fdra\n",
    "def get_fdra():\n",
    "    print(\"Getting Fdra...\")\n",
    "    url = 'https://services3.arcgis.com/T4QMspbfLg3qTGWY/arcgis/rest/services/Pacific_Northwest_Fire_Danger_Rating_Areas_(public)/FeatureServer/0/query?where=OBJECTID+%3E+-1&outFields=FDRAName,ParentDocName,PythonURL&f=pgeojson&token='\n",
    "    gdf = geojson_rest(url).to_crs(proj_crs)\n",
    "    return gdf\n",
    "gdf_fdra = get_fdra()\n",
    "\n",
    "gdf_fdra['key'] = gdf_fdra['ParentDocName'].str.replace('\\W', '', regex=True) + '_' + gdf_fdra['FDRAName'].str.replace('\\W', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c2b05-046f-4958-a628-c1eb658c6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for retrieving fems data\n",
    "class FemsFieldSample(object):\n",
    "    def __init__(self, gdf_select):\n",
    "        self.gdf_select = gdf_select\n",
    "        self.sites = None\n",
    "        self.site_ids = None\n",
    "        self.samples = None\n",
    "        self.fuels = None\n",
    "        self.gdf_samples = None\n",
    "\n",
    "    def get_sites(self):\n",
    "        #get field sample sites\n",
    "        fm_site_query = \"\"\"\n",
    "        query GetSites {\n",
    "            getSites(returnAll: true) {\n",
    "                sites {\n",
    "                    siteId\n",
    "                    siteName\n",
    "                    areaId\n",
    "                    areaName\n",
    "                    stateId\n",
    "                    stateName\n",
    "                    groupId\n",
    "                    groupName\n",
    "                    siteStartDate\n",
    "                    active\n",
    "                    siteStatus\n",
    "                    fuelModel\n",
    "                    fuelLoading\n",
    "                    slope\n",
    "                    aspect\n",
    "                    defaultEndMonth\n",
    "                    defaultBeginMonth\n",
    "                    remarks\n",
    "                    rawsId\n",
    "                    raws\n",
    "                    jurisdiction\n",
    "                    zoomLevel\n",
    "                    longitude\n",
    "                    latitude\n",
    "                    elevation\n",
    "                    timeZone\n",
    "                    timeZoneOffset\n",
    "                    mapWidth\n",
    "                    modifiedTime\n",
    "                    modifiedBy\n",
    "                    createdTime\n",
    "                    createdBy\n",
    "                    firstSampleDate\n",
    "                    latestSampleDate\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "        print(\"Getting Sites...\")\n",
    "        json = returnGraphQl(url_fuelmodel, fm_site_query, None)\n",
    "        df = pd.DataFrame(json['data']['getSites']['sites'])\n",
    "        gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['longitude'], df['latitude'])).set_crs(proj_crs)\n",
    "        gdf = gpd.clip(gdf, self.gdf_select)\n",
    "        self.sites = gdf\n",
    "        self.site_ids = [\", \".join(map(str, gdf.siteId.unique()))][0]\n",
    "\n",
    "    #get field sample samples\n",
    "    def get_samples(self):\n",
    "        \n",
    "        fm_sample_query = \"\"\"\n",
    "        query GetFuelSamples ($siteId: String!) {\n",
    "            getFuelSamples(\n",
    "                returnAll: false\n",
    "                sampleId: null\n",
    "                siteId: $siteId\n",
    "                startDate: \"1910-01-01T00:00+00\"\n",
    "                endDate: \"2050-01-01T00:00+00\"\n",
    "                filterBySampleType: \"All\"\n",
    "                filterByStatus: \"All\"\n",
    "                filterByCategory: \"All\"\n",
    "                filterBySubCategory: \"All\"\n",
    "                filterByMethod: \"All\"\n",
    "            ) {\n",
    "                fuelSamples {\n",
    "                    fuel_sample_id\n",
    "                    site_id\n",
    "                    fuel_id\n",
    "                    sub_category_id\n",
    "                    sub_category\n",
    "                    sample\n",
    "                    method_type\n",
    "                    status\n",
    "                    sample_average_value\n",
    "                    subSampleCount\n",
    "                    modified_time\n",
    "                    modified_by\n",
    "                    created_time\n",
    "                    created_by\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "        print(\"Getting Samples...\")\n",
    "        json = returnGraphQl(url_fuelmodel, fm_sample_query, {'siteId': self.site_ids})\n",
    "        df = pd.DataFrame(json['data']['getFuelSamples']['fuelSamples'])\n",
    "        df['datetime'] = pd.to_datetime(df['sample'], errors='coerce')\n",
    "        df['doy'] = df.datetime.dt.dayofyear\n",
    "        df = df.loc[(df.status == 'Submitted') | (df.status == 'Edited')]\n",
    "        self.samples = df\n",
    "\n",
    "    def get_fuels(self):\n",
    "        #get field sample fuels\n",
    "        fuels_sample_query = \"\"\"\n",
    "        query GetFuels {\n",
    "            getFuels(returnAll: true) {\n",
    "                fuel_id\n",
    "                category\n",
    "                fuel_type\n",
    "                scientific_name\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "        print(\"Getting Fuels...\")\n",
    "        json = returnGraphQl(url_fuelmodel, fuels_sample_query, None)\n",
    "        df = pd.DataFrame(json['data']['getFuels'])\n",
    "        self.fuels = df\n",
    "\n",
    "    def add_fuels_to_samples(self):\n",
    "        #add fuels data to samples data\n",
    "        self.samples['category'] = ''\n",
    "        self.samples['fuel_type'] = ''\n",
    "        self.samples['scientific_name'] = ''\n",
    "        for i, row in self.samples.iterrows():\n",
    "            r_fuel_id = self.samples.loc[i, 'fuel_id']\n",
    "            r_fuels = self.fuels.loc[self.fuels.fuel_id == r_fuel_id]\n",
    "            self.samples.loc[i, 'category'] = r_fuels['category'].values[0]\n",
    "            self.samples.loc[i, 'fuel_type'] = r_fuels['fuel_type'].values[0]\n",
    "            self.samples.loc[i, 'scientific_name'] = r_fuels['scientific_name'].values[0]\n",
    "\n",
    "    def make_gdf_samples(self):\n",
    "        df = self.sites.set_index('siteId').join(self.samples.set_index('site_id')) #note fems site id are currently different...\n",
    "        self.gdf_samples = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821eae90-a967-4ec9-9c63-347b5e285d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisData(object):   \n",
    "    \n",
    "    def __init__(self, gdf_select):\n",
    "        self.gdf_select = gdf_select\n",
    "        self.field_sample = FemsFieldSample(gdf_select)\n",
    "        self.sites = None\n",
    "        self.samples = None\n",
    "        self.fuels = None\n",
    "        self.raws = None\n",
    "        \n",
    "    def get_field_sample(self):\n",
    "        self.sites = self.field_sample.get_sites()\n",
    "        self.samples = self.field_sample.get_samples()\n",
    "        self.fuels = self.field_sample.get_fuels()\n",
    "        self.field_sample.add_fuels_to_samples()\n",
    "        self.field_sample.make_gdf_samples()\n",
    "\n",
    "    #get raws from wxx\n",
    "    def get_raws(self):\n",
    "        print(\"Getting Raws...\")\n",
    "        url_wxx = 'https://weather.nifc.gov/ords/prd/wx/station/statbaseline/0'\n",
    "        with urllib.request.urlopen(url_wxx) as url:\n",
    "            data = json.load(url)\n",
    "        df = pd.DataFrame(data['station_archive_baseline'])\n",
    "        df = df.loc[df.Class == 'Permanent']\n",
    "        df = df.loc[df.Status == 'A']\n",
    "        df = df.loc[df['Ownership Type'] == 'FIRE']\n",
    "        #remove leading zeros from station id, fems does not recognize (station id is an int in fems, not a str)\n",
    "        df['NWS ID'] = df['NWS ID'].str.lstrip('0')\n",
    "        gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude), crs=proj_crs)\n",
    "        self.raws = gdf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5774ac-e60f-48bb-965d-75caeadfec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fdra.ParentDocName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b58ce2-5035-4a6e-9fff-90823acd2708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general analysis area of interest, script is setup for this to be fdop level\n",
    "#can also just load up the whole gacc here\n",
    "gdf_select_aoi = gdf_fdra#.loc[gdf_fdra.ParentDocName == 'Southwest Oregon']\n",
    "analysis_data_all = AnalysisData(gdf_select_aoi)\n",
    "analysis_data_all.get_field_sample()\n",
    "analysis_data_all.get_raws()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da945e2-9b69-41f3-8d6a-14edb4a08e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GsiAnalysisData(object):\n",
    "\n",
    "    def get_fems_wx(sta_id): #sta_id is nws_id, fems was going away from nws_id but now not so much...\n",
    "        wx_query = \"\"\"\n",
    "        query WeatherObs ($stationIds: String!) {\n",
    "            weatherObs(\n",
    "                startDateTimeRange: \"2005-01-01T00:00:00Z\"\n",
    "                endDateTimeRange: \"2025-12-31T00:00:00Z\"\n",
    "                stationIds: $stationIds\n",
    "            ) {\n",
    "                data {\n",
    "                    station_id\n",
    "                    station_name\n",
    "                    latitude\n",
    "                    longitude\n",
    "                    elevation\n",
    "                    zoom_level\n",
    "                    station_type\n",
    "                    observation_time\n",
    "                    observation_time_offset\n",
    "                    display_hour\n",
    "                    display_hour_offset\n",
    "                    display_date\n",
    "                    temperature\n",
    "                    relative_humidity\n",
    "                    hourly_precip\n",
    "                    hr24Precipitation\n",
    "                    hr48Precipitation\n",
    "                    hr72Precipitation\n",
    "                    wind_speed\n",
    "                    wind_direction\n",
    "                    peak_gust_speed\n",
    "                    peak_gust_dir\n",
    "                    sol_rad\n",
    "                    snow_flag\n",
    "                    observation_type\n",
    "                    hex\n",
    "                    t_flag\n",
    "                    rh_flag\n",
    "                    pcp_flag\n",
    "                    ws_flag\n",
    "                    wa_flag\n",
    "                    sr_flag\n",
    "                    gs_flag\n",
    "                    ga_flag\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "        json_wx = returnGraphQl(url_climatology, wx_query, {\"stationIds\": sta_id})\n",
    "        df = pd.DataFrame(json_wx['data']['weatherObs']['data'])\n",
    "        df.observation_time = pd.to_datetime(df.observation_time).dt.tz_convert(tz_local)\n",
    "        df = df.loc[df.observation_type=='O']\n",
    "        df['doy'] = df.observation_time.dt.dayofyear\n",
    "        return df\n",
    "\n",
    "    def __init__(self, gdf_select, analysis_data_all):\n",
    "        self.analysis_data_all = analysis_data_all\n",
    "        self.gdf_select = gdf_select\n",
    "        self.fdop_name = gdf_select.ParentDocName.values[0]\n",
    "        self.fdra_name = gdf_select.FDRAName.values[0]\n",
    "        self.fdop_dir = ''.join(char for char in self.fdop_name if char.isalnum())\n",
    "        self.fdra_dir = ''.join(char for char in self.fdra_name if char.isalnum())\n",
    "        self.raws = None # gpd.clip(analysis_data_all.field_sample.gdf_samples\n",
    "        self.sites = None\n",
    "        self.samples_herb = None\n",
    "        self.samples_shrub = None\n",
    "        self.samples_herb_group = None\n",
    "        self.samples_shrub_group = None\n",
    "        self.wx = None\n",
    "\n",
    "    def clip_data(self):\n",
    "        self.raws = gpd.clip(self.analysis_data_all.raws, self.gdf_select)\n",
    "        self.sites = gpd.clip(self.analysis_data_all.field_sample.gdf_samples, self.gdf_select)\n",
    "\n",
    "    def prep_data(self):\n",
    "        self.samples_shrub = self.sites.loc[(self.sites.category == 'Shrub')]\n",
    "        self.samples_herb = self.sites.loc[(self.sites.category == 'Grass') | (self.sites.category == 'Forb')]\n",
    "        self.samples_shrub_group = self.samples_shrub.groupby('doy')[['sample_average_value']].mean()\n",
    "        self.samples_herb_group = self.samples_herb.groupby('doy')[['sample_average_value']].mean()\n",
    "        self.samples_shrub_group['rolling_mean'] = self.samples_shrub_group.sample_average_value.rolling(10, center=True, min_periods=5).mean()\n",
    "        self.samples_herb_group['rolling_mean'] = self.samples_herb_group.sample_average_value.rolling(10, center=True, min_periods=5).mean()\n",
    "        #remove crazy values\n",
    "        self.samples_shrub_group.loc[self.samples_shrub_group.rolling_mean > 500] = np.nan\n",
    "        self.samples_herb_group.loc[self.samples_herb_group.rolling_mean > 500] = np.nan \n",
    "\n",
    "    def get_wx(self):\n",
    "        l = []\n",
    "        for sta_id in self.raws['NWS ID'].unique():\n",
    "            sta_id = str(sta_id)\n",
    "            try:\n",
    "                print(\"Getting \" + sta_id + \" Wx...\")\n",
    "                df = GsiAnalysisData.get_fems_wx(sta_id)\n",
    "                l.append(df)\n",
    "            except Exception as e:\n",
    "                print(\"Station \" + sta_id + \" Failed...\")\n",
    "        self.wx = pd.concat(l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d178d-059c-4bd8-9457-6baa390d6e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot fdra field sample fuels and mean (calibration target)\n",
    "from cycler import cycler\n",
    "def plot_analysis_area_fuels(analysis_data):\n",
    "    output_dir = cwd + analysis_data.fdop_dir\n",
    "    make_dir(cwd + analysis_data.fdop_dir)\n",
    "    plt.rcParams['axes.prop_cycle'] = cycler('color', plt.get_cmap('tab20c_r').colors)\n",
    "    shrub = analysis_data.samples_shrub.copy()\n",
    "    herb = analysis_data.samples_herb.copy()\n",
    "    \n",
    "    shrub_nyears = len(shrub.datetime.dt.year.unique())\n",
    "    herb_nyears = len(herb.datetime.dt.year.unique())\n",
    "    shrub_grp = analysis_data.samples_shrub_group.copy()\n",
    "    herb_grp = analysis_data.samples_herb_group.copy()\n",
    "    shrub_grp_sp = shrub.groupby(['fuel_type', 'doy'])[['sample_average_value']].mean().unstack().T \\\n",
    "        .reset_index().drop(['level_0'], axis=1).set_index('doy', drop=True)\n",
    "    herb_grp_sp = herb.groupby(['fuel_type', 'doy'])[['sample_average_value']].mean().unstack().T \\\n",
    "        .reset_index().drop(['level_0'], axis=1).set_index('doy', drop=True)\n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=(4,5.5))\n",
    "    if len(shrub_grp_sp.columns) == 1:\n",
    "        label = shrub_grp_sp.columns[0]\n",
    "    else:\n",
    "        label = shrub_grp_sp.columns\n",
    "    ax1.plot(shrub_grp_sp, linewidth=0.5, label=label)\n",
    "    ax1.plot(shrub_grp.index, shrub_grp.sample_average_value, color='black', label='Sample Mean')\n",
    "    ax1.plot(shrub_grp.index, shrub_grp.rolling_mean, color='red', label='Sample Rolling Mean')\n",
    "    ax1.set_xlim(0, 365)\n",
    "    ax1.set_ylim(0, 250)\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "    ax1.set_title('Shrub:' + ' Years(n) = ' + str(shrub_nyears))\n",
    "    ax1.legend(prop={'size': 6})\n",
    "    if len(herb_grp_sp.columns) == 1:\n",
    "        label = herb_grp_sp.columns[0]\n",
    "    else:\n",
    "        label = herb_grp_sp.columns\n",
    "    ax2.plot(herb_grp_sp, linewidth=0.5, label=label)\n",
    "    ax2.plot(herb_grp.index, herb_grp.sample_average_value, color='black', label='Sample Mean')\n",
    "    ax2.plot(herb_grp.index, herb_grp.rolling_mean, color='red', label='Sample Rolling Mean')\n",
    "    ax2.set_xlim(0, 365)\n",
    "    ax2.set_ylim(0, 250)\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "    ax2.set_title('Grass & Forb:' + ' Years(n) = ' + str(herb_nyears))\n",
    "    ax2.legend(prop={'size': 6})\n",
    "    plt.suptitle(analysis_data.fdop_name + ' ' + analysis_data.fdra_name)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(output_dir + '\\\\samples_' + analysis_data.fdop_dir + '_' + analysis_data.fdra_dir + '.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44157ef-0e85-403b-936c-8413092b464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot field sample data to see if enough data for gsi calibration\n",
    "def make_field_sample_plots(gdf_fdra):\n",
    "    for fdra_key in gdf_fdra.key.unique():\n",
    "        gdf_select_fdra = gdf_fdra.loc[gdf_fdra.key == fdra_key]\n",
    "        analysis_data = GsiAnalysisData(gdf_select_fdra, analysis_data_all)\n",
    "        analysis_data.clip_data()\n",
    "        analysis_data.prep_data()\n",
    "        if analysis_data.sites.empty != True:\n",
    "            plot_analysis_area_fuels(analysis_data)\n",
    "make_field_sample_plots(gdf_fdra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f4b45-f073-4ccf-9bc2-6edd79757c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_gsi(analysis_data, herb_or_woody):\n",
    "\n",
    "    #plot_analysis_area_fuels(field_sample)\n",
    "\n",
    "    if not use_prcp:\n",
    "    \tfname_ext = '_VpdMax'\n",
    "    if use_prcp:\n",
    "    \tfname_ext = '_Prcp'\n",
    "\n",
    "    analysis_data_wx = analysis_data.wx.copy()\n",
    "    analysis_data_raws = analysis_data.raws.copy()\n",
    "    samples_shrub = analysis_data.samples_shrub_group.copy()\n",
    "    samples_herb = analysis_data.samples_herb_group.copy()\n",
    "    output_dir = cwd + analysis_data.fdop_dir + '\\\\' + analysis_data.fdra_dir\n",
    "    make_dir(output_dir)\n",
    "\n",
    "    if herb_or_woody == 'Woody':\n",
    "        samples = samples_shrub.copy()\n",
    "    elif herb_or_woody == 'Herbaceous':\n",
    "        samples = samples_herb.copy()\n",
    "    else:\n",
    "        print(\"Options are Woody or Herbaceous...\")\n",
    "        raise ValueError\n",
    "\n",
    "    sta_results_list = []\n",
    "    for sta_id in analysis_data_wx.station_id.unique():\n",
    "        print(\"Calibrating Gsi \" + str(sta_id) + \"...\")\n",
    "        df_wx = analysis_data_wx.loc[analysis_data_wx.station_id == sta_id, :].copy()\n",
    "        sta_id = str(sta_id)\n",
    "        st_yr = str(df_wx.observation_time.dt.year.values.min())\n",
    "        end_yr = str(df_wx.observation_time.dt.year.values.max())\n",
    "        chart_yrs = \"(\" + st_yr + \"-\" + end_yr + \")\"\n",
    "\n",
    "        #---Most of the following was lifted from from Matt Jolly's Git NFDR Master Class before alteration---#\n",
    "        # This function will calcuraws_late Photoperiod from raws_latitude and Day of Year\n",
    "        RADPERDAY = 0.017214\n",
    "        RADPERDEG = 0.01745329\n",
    "        MINDECL = -0.4092797\n",
    "        SECPERRAD = 13750.9871\n",
    "        DAYSOFF = 10.25\n",
    "        #Inputs: raws_lat = raws_latitude in Degrees, yday is the day of the year.\n",
    "        #Returns: Daylength in seconds\n",
    "        def CalcDayl(raws_lat, julian_day):\n",
    "                # Daylength function from MT-CLIM */\n",
    "                raws_lat = raws_lat * RADPERDEG\n",
    "                if raws_lat > 1.5707:\n",
    "                    raws_lat = 1.5707\n",
    "                if raws_lat < -1.5707:\n",
    "                    raws_lat = -1.5707\n",
    "                cosraws_lat = cos(raws_lat)\n",
    "                sinraws_lat = sin(raws_lat)\n",
    "\n",
    "                #* calcuraws_late cos and sin of declination */\n",
    "                decl = MINDECL * cos((julian_day + DAYSOFF) * RADPERDAY)\n",
    "                cosdecl = cos(decl)\n",
    "                sindecl = sin(decl)\n",
    "                cosegeom = cosraws_lat * cosdecl\n",
    "                sinegeom = sinraws_lat * sindecl\n",
    "                coshss = -(sinegeom) / cosegeom\n",
    "                if coshss < -1.0:\n",
    "                    coshss = -1.0  # 24-hr daylight */\n",
    "                if coshss > 1.0:\n",
    "                    coshss = 1.0    # 0-hr daylight */\n",
    "                hss = acos(coshss)                # hour angle at sunset (radians) */\n",
    "                #* daylength (seconds) */\n",
    "                return 2.0 * hss * SECPERRAD\n",
    "        # Calcuate Daylength for each row                          \n",
    "        df_wx['Dayl'] = df_wx.apply(lambda row: CalcDayl(df_wx.latitude.round(0)[0], int(row['doy'])), axis=1)\n",
    "\n",
    "        # Function to calculate the Saturation Vapor Pressure for a given temperature.\n",
    "        # Note: Function converts internally from F to C.\n",
    "        def CalcVP(tempF):\n",
    "            tmpC =  (tempF - 32.0) / 1.8\n",
    "            vp = 610.7 * exp((17.38 * tmpC)/(239 + tmpC))\n",
    "            return vp\n",
    "\n",
    "        # Calculate the VPD from RH and temperature\n",
    "        def CalcVPD(RH, TempF):\n",
    "            vp = CalcVP(TempF)\n",
    "            vpd = vp - (RH / 100) * vp\n",
    "            if(vpd < 0.0):\n",
    "                vpd = 0.0;\n",
    "            return vpd\n",
    "\n",
    "        # Use of resample requires datetime as index\n",
    "        df_wx_hourly = df_wx.set_index('observation_time')\n",
    "\n",
    "        Tmin = pd.DataFrame({\"Tmin\": df_wx_hourly['temperature'].resample('D').min()})  \n",
    "        Tmax = pd.DataFrame({\"Tmax\": df_wx_hourly['temperature'].resample('D').max()})\n",
    "        Tavg = pd.DataFrame({\"Tavg\": df_wx_hourly['temperature'].resample('D').mean()})\n",
    "        Dayl = pd.DataFrame({\"Dayl\": df_wx_hourly['Dayl'].resample('D').mean()})\n",
    "        Prcp = pd.DataFrame({\"Prcp\": df_wx_hourly['hourly_precip'].resample('D').sum()})\n",
    "        RHmin = pd.DataFrame({\"RHmin\": df_wx_hourly['relative_humidity'].resample('D').min()})\n",
    "        RHmax = pd.DataFrame({\"RHmax\": df_wx_hourly['relative_humidity'].resample('D').max()})\n",
    "        RHavg = pd.DataFrame({\"RHavg\": df_wx_hourly['relative_humidity'].resample('D').mean()})\n",
    "\n",
    "        df_wx_daily = pd.concat([Tmax, Tmin, Tavg, RHmax, RHmin, RHavg, Dayl, Prcp], axis=1)\n",
    "        df_wx_daily['observation_time'] = df_wx_daily.index\n",
    "        df_wx_daily['VPDAvg'] = df_wx_daily.apply(lambda row: CalcVPD(row['RHavg'], row['Tavg']),axis=1)\n",
    "        df_wx_daily['VPDMax'] = df_wx_daily.apply(lambda row: CalcVPD(row['RHmin'], row['Tmax']),axis=1)\n",
    "        df_wx_daily['TminC'] =  (df_wx_daily.Tmin - 32.0) * 5.0 / 9.0; # Convert Tmin from Fahrenheit to celcuius\n",
    "        df_wx_daily['Prcp_RT'] = df_wx_daily['Prcp'].rolling(28).sum()\n",
    "\n",
    "        # GSI indicator/ramp function\n",
    "        #change from mj version to use arrays instead of apply by row (slow)\n",
    "        def Ind(Var, Low, Up):\n",
    "            with np.errstate(divide='ignore'): #ignore divide by zero runtimewarning\n",
    "                arr = (Var - Low) / (Up - Low) #return the proportion\n",
    "                arr[np.isinf(arr)] = 0 #replace inf from divide by zero with 0\n",
    "            arr[Var > Up] = 1 #if the variable is greater than the upper limit, return 1\n",
    "            arr[Var < Low] = 0 #if the variable is less than the lower limit, return 0\n",
    "            arr[Up == Low] = 0 #upper (Up) and lower (Low) can't be the same\n",
    "            return arr\n",
    "\n",
    "        def make_setting_combinations(use_prcp):\n",
    "            #use station values for ranges\n",
    "            t_min = round(df_wx_daily['TminC'].min() / 2) * 2\n",
    "            if t_min < -10:\n",
    "                t_min = -10\n",
    "            t_max = round(df_wx_daily['TminC'].max() / 2) * 2\n",
    "            if t_max > 22:\n",
    "                t_max = 22\n",
    "\n",
    "            if use_vpdmax:\n",
    "                vpd_min = round(df_wx_daily.VPDMax.min() / 50) * 50\n",
    "                if vpd_min < 250:\n",
    "                    vpd_min = 0\n",
    "                else:\n",
    "                    vpd_min = round(df_wx_daily.VPDMax.min() / 250) * 250\n",
    "                vpd_max = round(df_wx_daily.VPDMax.max() / 250) * 250\n",
    "            else:\n",
    "                vpd_min = round(df_wx_daily.VPDAvg.min() / 50) * 50\n",
    "                if vpd_min < 250:\n",
    "                    vpd_min = 0\n",
    "                else:\n",
    "                    vpd_min = round(df_wx_daily.VPDAvg.min() / 250) * 250\n",
    "                vpd_max = round(df_wx_daily.VPDAvg.max() / 250) * 250                    \n",
    "            \n",
    "            dayl_min = int(df_wx_daily.Dayl.min() / 3600) * 3600\n",
    "            dayl_max = int(df_wx_daily.Dayl.max() / 3600) * 3600        \n",
    "                \n",
    "            #careful here, easy to get to a million possible combinations pretty quickly\n",
    "            TminLowRange = np.arange(t_min, 0, 2) #-10\n",
    "            TminHighRange = np.arange(0, t_max, 2) #25\n",
    "            VPDLowRange = np.arange(vpd_min, 3500, 250) #0\n",
    "            VPDUpRange = np.arange(3500, vpd_max, 250) #10000\n",
    "            DaylLowRange = np.arange(dayl_min, dayl_max, 3600)\n",
    "            DaylUpRange = np.arange(dayl_min + 3600, dayl_max + 3600, 3600)\n",
    "            if use_prcp:\n",
    "                PrcpRTLow = [0.25, 0.5, 0.75, 1.0]\n",
    "                PrcpRTUp = [1.25, 1.5, 2.0, 2.25]\n",
    "                combinations = np.array(list(itertools.product(TminLowRange, TminHighRange, VPDLowRange, \\\n",
    "                    VPDUpRange, DaylLowRange, DaylUpRange, PrcpRTLow, PrcpRTUp)))\n",
    "            else:\n",
    "                combinations = np.array(list(itertools.product(TminLowRange, TminHighRange, VPDLowRange, \\\n",
    "                    VPDUpRange, DaylLowRange, DaylUpRange)))\n",
    "            return combinations\n",
    "\n",
    "        if herb_or_woody == 'Woody':\n",
    "            LFMMax = 250 #samples.sample_average_value.max()\n",
    "            if samples.sample_average_value.min() >= 60:\n",
    "                LFMMin = samples.sample_average_value.min()\n",
    "            else:\n",
    "                LFMMin = 60\n",
    "        else:\n",
    "            LFMMax = 300 #samples.sample_average_value.max()\n",
    "            if samples.sample_average_value.min() >= 30:\n",
    "                LFMMin = samples.sample_average_value.min()\n",
    "            else:\n",
    "                LFMMin = 30            \n",
    "\n",
    "        if use_prcp:\n",
    "            GUThresh = 0.3\n",
    "        else:\n",
    "            GUThresh = 0.5\n",
    "\n",
    "        samples.rename({'rolling_mean': 'FuelMoisture'}, axis=1, inplace=True)\n",
    "\n",
    "        def calibrate_gsi(df_wx_daily, samples, use_vpdmax, use_prcp):\n",
    "            df = df_wx_daily.copy()\n",
    "            combinations = make_setting_combinations(use_prcp)\n",
    "            combo_list = []\n",
    "            combo_len = len(combinations)\t\n",
    "            arr_len = len(df)\n",
    "\n",
    "            m = (LFMMax - LFMMin) / (1 - GUThresh)\n",
    "            m_arr = np.repeat(m, arr_len)\n",
    "            b = LFMMax - m\n",
    "            b_arr = np.repeat(b, arr_len)\n",
    "            guthresh_arr = np.repeat(GUThresh, arr_len)\n",
    "\n",
    "            for combination in combinations:\n",
    "                try:\n",
    "                    tmin_arr = Ind(df.TminC.values, \\\n",
    "                        np.repeat(combination[0], arr_len), np.repeat(combination[1], arr_len))\t\t\n",
    "                    df['TminInd'] = tmin_arr.tolist()\n",
    "\n",
    "                    if use_vpdmax:\n",
    "                        vpd_arr = Ind(df.VPDMax.values, \\\n",
    "                            np.repeat(combination[2], arr_len), np.repeat(combination[3], arr_len))\n",
    "                    else:\n",
    "                        vpd_arr = Ind(df.VPDAvg.values, \\\n",
    "                            np.repeat(combination[2], arr_len), np.repeat(combination[3], arr_len))\n",
    "                    df['VPDInd'] = vpd_arr.tolist()\n",
    "                    df['VPDInd'] = 1 - df['VPDInd']\n",
    "\n",
    "                    dayl_arr = Ind(df.Dayl.values, \\\n",
    "                        np.repeat(combination[4], arr_len), np.repeat(combination[5], arr_len))\t\n",
    "                    df['DaylInd'] = dayl_arr.tolist()\n",
    "\n",
    "                    if use_prcp:\n",
    "                        prcp_arr = Ind(df.Prcp_RT.values, \\\n",
    "                            np.repeat(combination[6], arr_len), np.repeat(combination[7], arr_len))\n",
    "                        df['PrcpInd'] = prcp_arr.tolist()\n",
    "                        df['iGSI'] = df['TminInd'] * df['DaylInd'] * df['VPDInd'] * df['PrcpInd']\n",
    "                    else:\n",
    "                        df['iGSI'] = df['TminInd'] * df['DaylInd'] * df['VPDInd']\t\n",
    "\n",
    "                    df['GSI'] = df['iGSI'].rolling(28).mean()\n",
    "\n",
    "                    gsi_arr = df['GSI'].values\n",
    "\n",
    "                    df['FuelMoisture'] = np.where(gsi_arr >= guthresh_arr, m_arr * gsi_arr + b_arr, LFMMin)\n",
    "                    df_fm = pd.DataFrame(df.FuelMoisture.groupby(df.observation_time.dt.dayofyear).mean())\n",
    "                    join = samples.join(df_fm, lsuffix='_NFMD', rsuffix='_RAWS').dropna()\n",
    "                    #score = 1 - spatial.distance.cosine(join.Percent_NFMD, join.Percent_RAWS)\n",
    "                    score = sum(abs(join.FuelMoisture_NFMD - join.FuelMoisture_RAWS))\n",
    "                    if use_prcp:\n",
    "                        df_score = pd.DataFrame([combination[0], combination[1], combination[2], \n",
    "                            combination[3], combination[4], combination[5], \n",
    "                            combination[6], combination[7], score]).T \n",
    "                    else:\n",
    "                        df_score = pd.DataFrame([combination[0], combination[1], combination[2], \n",
    "                            combination[3], combination[4], combination[5], score]).T \t\t\t\n",
    "                    combo_list.append(df_score)\n",
    "                    combo_len -= 1\n",
    "                    #print(combo_len, score)\n",
    "                except RuntimeWarning:\n",
    "                    pass\n",
    "\n",
    "            res = pd.concat(combo_list)\n",
    "            if use_prcp:\n",
    "                res.rename({0: 'TminLow', 1: 'TminUp', 2: 'VPDLow', 3: 'VPDUp', 4: 'DaylLow', 5: 'DaylUp', 6: 'PrcpRTLow', \n",
    "                    7: 'PrcpRTUp', 8: 'Score'}, axis=1, inplace=True)\n",
    "            else:\n",
    "                res.rename({0: 'TminLow', 1: 'TminUp', 2: 'VPDLow', 3: 'VPDUp', 4: 'DaylLow', 5: 'DaylUp', 6: 'Score'}, axis=1, inplace=True)\n",
    "            res.reset_index(drop=True, inplace=True)\n",
    "            res.sort_values(by='Score', inplace=True)\n",
    "            return res\n",
    "        res = calibrate_gsi(df_wx_daily, samples, use_vpdmax, use_prcp)\n",
    "        top_res = res.head(1).copy()\n",
    "        top_res.loc[:, 'LFMMax'] = LFMMax\n",
    "        top_res.loc[:, 'LFMMin'] = LFMMin\n",
    "        top_res.loc[:, 'GUThresh'] = GUThresh\t\n",
    "        top_res.loc[:, 'NwsId'] = sta_id\n",
    "        top_res.loc[:, 'Area'] = analysis_data.fdop_name + ' ' +  analysis_data.fdra_name      \n",
    "        if use_prcp:\n",
    "            cols = ['Area', 'NwsId', 'TminLow', 'TminUp', 'VPDLow', 'VPDUp',\t\\\n",
    "            'DaylLow', 'DaylUp', 'PrcpRTLow', 'PrcpRTUp', \\\n",
    "            'LFMMax', 'LFMMin', 'GUThresh', 'Score']\n",
    "        else:\n",
    "            cols = ['Area', 'NwsId', 'TminLow', 'TminUp', 'VPDLow', 'VPDUp',\t\\\n",
    "            'DaylLow', 'DaylUp', 'LFMMax', 'LFMMin', 'GUThresh', 'Score']\n",
    "        top_res = top_res[cols]\n",
    "        top_res.loc[:, 'WxStartYr'] = st_yr\n",
    "        top_res.loc[:, 'WxEndYr'] = end_yr\n",
    "        top_res.loc[:, 'SampleType'] = woody_or_herb \n",
    "        \n",
    "        sta_results_list.append(top_res)\n",
    "\n",
    "        def calc_gsi_plot(df_wx_daily, use_vpdmax, use_prcp):\n",
    "            df = df_wx_daily.copy()\n",
    "\n",
    "            def Ind_Plot(Var, Low, Up):\n",
    "                # Make sure all the input variables are numbers\n",
    "                Var = float(Var)\n",
    "                Low = float(Low)\n",
    "                Up = float(Up)\n",
    "                if(Up == Low):  # Upper (Up) and Lower (Low) can't be the same\n",
    "                    return 0\n",
    "                if( Var < Low):  # If the variables is less than the lower limit, return 0\n",
    "                    return 0\n",
    "                elif(Var > Up):  # If the variables is greater than the upper limit, return 1\n",
    "                    return 1\n",
    "                else:            # If the variables is between the lower and upper limits, return the proportion\n",
    "                    return (Var - Low) / (Up - Low)\n",
    "\n",
    "            df['TminInd'] = df.apply(lambda row: Ind_Plot(row['TminC'], Tmin[0], Tmin[1]), axis=1)\n",
    "            if use_vpdmax:\n",
    "                df['VPDInd'] = df.apply(lambda row: 1 - Ind_Plot(row['VPDMax'], VPD[0], VPD[1]), axis=1)\n",
    "            else:\n",
    "                df['VPDInd'] = df.apply(lambda row: 1 - Ind_Plot(row['VPDAvg'], VPD[0], VPD[1]), axis=1)\n",
    "            df['DaylInd'] = df.apply(lambda row: Ind_Plot(row['Dayl'], Dayl[0], Dayl[1]), axis=1)\n",
    "            if use_prcp:\n",
    "                df['PrcpInd'] = df.apply(lambda row: Ind_Plot(row['Prcp_RT'], Prcp[0], Prcp[1]), axis=1)\n",
    "                df['iGSI'] = df['TminInd'] * df['DaylInd'] * df['VPDInd'] * df['PrcpInd']\n",
    "            else:\n",
    "                df['iGSI'] = df['TminInd'] * df['DaylInd'] * df['VPDInd']\n",
    "            df['GSI'] = df['iGSI'].rolling(28).mean()\n",
    "            df['FuelMoisture'] = df.apply(lambda row: m * row.GSI + b if row.GSI >= GUThresh else LFMMin, axis=1)\n",
    "            return df\n",
    "\n",
    "        def plot_default_gsi(df_wx_daily, samples, use_vpdmax, use_prcp, ax):\n",
    "            df_fm = calc_gsi_plot(df_wx_daily, use_vpdmax, use_prcp)\n",
    "            df_fm.FuelMoisture.groupby(df_fm.observation_time.dt.dayofyear).mean().plot(color='grey', label=\"Mean\", ax=ax)\n",
    "            df_fm.FuelMoisture.groupby(df_fm.observation_time.dt.dayofyear).min().plot(color='#2b83ba', label=\"Min\", ax=ax)\n",
    "            df_fm.FuelMoisture.groupby(df_fm.observation_time.dt.dayofyear).max().plot(color='#d7191c', label=\"Max\", ax=ax)\n",
    "            samples.FuelMoisture.plot(color='black', linestyle='dashed', label=\"Sample Mean\", ax=ax)\n",
    "            ax.set_xlabel(\"Day of Year\")\n",
    "            ax.set_ylabel(\"Live Fuel Moisture (% dry wt)\")\n",
    "            ax.set_title(\"Default GSI Settings\") #\\n\" + psa_code + \" RAWS \" + sta_id + \" (2005-2023)\")\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "            ax.text(0, samples.FuelMoisture.max(), 'Tmin: ' + str(Tmin[0]) + ', ' + str(Tmin[1]) + \\\n",
    "                '\\nVPD: ' + str(VPD[0]) + ', ' + str(VPD[1]) + \\\n",
    "                '\\nDayl: ' + str(Dayl[0]) + ', ' + str(Dayl[1]) + \\\n",
    "                '\\nPrcp: ' + str(Prcp[0]) + ', ' + str(Prcp[1]) + \\\n",
    "                '\\nUseVPDMax: ' + str(use_vpdmax) + \\\n",
    "                '\\nUsePrecp: ' + str(use_prcp) + '\\nLFMMax: ' + str(round(LFMMax, 0)) + '\\nLFMMin: ' + \\\n",
    "                str(round(LFMMin, 0)) + '\\nGUThresh: ' + str(GUThresh), fontsize=8, ha='left', va='top')\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "        def plot_calib_gsi(df_wx_daily, samples, use_vpdmax, use_prcp, ax):\n",
    "            df_fm = calc_gsi_plot(df_wx_daily, use_vpdmax, use_prcp)\n",
    "            df_fm.FuelMoisture.groupby(df_fm.observation_time.dt.dayofyear).mean().plot(color='grey', label=\"Mean\", ax=ax)\n",
    "            df_fm.FuelMoisture.groupby(df_fm.observation_time.dt.dayofyear).min().plot(color='#2b83ba', label=\"Min\", ax=ax)\n",
    "            df_fm.FuelMoisture.groupby(df_fm.observation_time.dt.dayofyear).max().plot(color='#d7191c', label=\"Max\", ax=ax)\n",
    "            samples.FuelMoisture.plot(color='black', linestyle='dashed', label=\"Sample Mean\", ax=ax)\n",
    "            ax.set_xlabel(\"Day of Year\")\n",
    "            ax.set_ylabel(\"Live Fuel Moisture (% dry wt)\")\n",
    "            ax.set_title(\"Adjusted GSI Settings\") #\\n\" + psa_code + \" RAWS \" + sta_id + \" (2005-2023)\")\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "            ax.text(0, samples.FuelMoisture.max(), 'Tmin: ' + str(Tmin[0]) + ', ' + str(Tmin[1]) + \\\n",
    "                '\\nVPD: ' + str(VPD[0]) + ', ' + str(VPD[1]) + \\\n",
    "                '\\nDayl: ' + str(Dayl[0]) + ', ' + str(Dayl[1]) + \\\n",
    "                '\\nPrcp: ' + str(Prcp[0]) + ', ' + str(Prcp[1]) + \\\n",
    "                '\\nUseVPDMax: ' + str(use_vpdmax) + \\\n",
    "                '\\nUsePrecp: ' + str(use_prcp) + '\\nLFMMax: ' + str(round(LFMMax, 0)) + '\\nLFMMin: ' + \\\n",
    "                str(round(LFMMin, 0)) + '\\nGUThresh: ' + str(GUThresh), fontsize=8, ha='left', va='top')\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(5, 8))\n",
    "\n",
    "        #GSI defaults\n",
    "        Tmin = (-2, 5)\n",
    "        VPD = (1956, 3882)\n",
    "        Dayl = (39600, 43200)\n",
    "        Prcp = (0.4, 0.8)\n",
    "        GUThresh = 0.3\n",
    "        if herb_or_woody == 'Woody':\n",
    "            LFMMax = 250\n",
    "            LFMMin = 60\n",
    "        else:\n",
    "            LFMMax = 300\n",
    "            LFMMin = 30            \n",
    "        m = (LFMMax - LFMMin) / (1 - GUThresh)\n",
    "        b = LFMMax - m\n",
    "        plot_default_gsi(df_wx_daily, samples, use_vpdmax=use_vpdmax, use_prcp=True, ax=ax1)\n",
    "\n",
    "        #calib GSI\n",
    "        Tmin = (res.head(1).TminLow.values[0], res.head(1).TminUp.values[0])\n",
    "        VPD = (res.head(1).VPDLow.values[0], res.head(1).VPDUp.values[0])\n",
    "        Dayl = (res.head(1).DaylLow.values[0], res.head(1).DaylUp.values[0])\n",
    "        if use_prcp:\n",
    "            Prcp = (res.head(1).PrcpRTLow.values[0], res.head(1).PrcpRTUp.values[0])\n",
    "        else:\n",
    "            Prcp = (np.nan, np.nan)\n",
    "            \n",
    "        if herb_or_woody == 'Woody':\n",
    "            LFMMax = 250 #samples.sample_average_value.max()\n",
    "            if samples.sample_average_value.min() >= 60:\n",
    "                LFMMin = samples.sample_average_value.min()\n",
    "            else:\n",
    "                LFMMin = 60\n",
    "        else:\n",
    "            LFMMax = 300 #samples.sample_average_value.max()\n",
    "            if samples.sample_average_value.min() >= 30:\n",
    "                LFMMin = samples.sample_average_value.min()\n",
    "            else:\n",
    "                LFMMin = 30   \n",
    "            \n",
    "        if use_prcp:\n",
    "            GUThresh = 0.3\n",
    "        else:\n",
    "            GUThresh = 0.5\n",
    "        m = (LFMMax - LFMMin) / (1 - GUThresh)\n",
    "        b = LFMMax - m\n",
    "        plot_calib_gsi(df_wx_daily, samples, use_vpdmax=use_vpdmax, use_prcp=use_prcp, ax=ax2)\n",
    "\n",
    "        plt.suptitle(analysis_data.fdop_name + ' ' + analysis_data.fdra_name  + '\\n' \\\n",
    "             + woody_or_herb + \" Calibration\" + \"\\nRAWS \" + sta_id + \" \" + chart_yrs)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir + '\\\\calib_' + sta_id + '_' + woody_or_herb + fname_ext + '.jpg')\n",
    "        plt.close()\n",
    "    res = pd.concat(sta_results_list)\n",
    "    res.to_csv(output_dir + '\\\\results_' + woody_or_herb + fname_ext + '.csv')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5f034-fc76-471b-9a13-7f417e7b4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fdra.key.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48de284-67c9-40d1-b043-1fc92a80fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select which fdra have enough field sample data to calibrate to (review output from plot_analysis_area_fuels above)\n",
    "#restart here for any other fdra in list above\n",
    "gdf_select = gdf_fdra.loc[gdf_fdra.key.isin(['CentralOregon_HighDesert', 'CentralOregon_ColumbiaPlateau', 'CentralOregon_EastSlope', 'CentralOregon_Monument'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab16f57-9072-4d37-9b72-6d0db2ee04de",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_prcp = False\n",
    "use_vpdmax = True\n",
    "woody_or_herb = 'Woody' #options are 'Woody' or 'Herbaceous'\n",
    "\n",
    "#make analysis data, getting hourly weather for 2005 through present takes a while, so does gsi calibration...best to run overnight\n",
    "for fdra_key in gdf_select.key.unique():\n",
    "    gdf_select_fdra = gdf_fdra.loc[gdf_fdra.key == fdra_key]\n",
    "    analysis_data = GsiAnalysisData(gdf_select_fdra, analysis_data_all)\n",
    "    analysis_data.clip_data()\n",
    "    analysis_data.prep_data()\n",
    "    analysis_data.get_wx()\n",
    "    res = calibrate_gsi(analysis_data, woody_or_herb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44dad9-cc26-406c-9232-e76705ec9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_prcp = False\n",
    "use_vpdmax = True\n",
    "woody_or_herb = 'Woody' #options are 'Woody' or 'Herbaceous'\n",
    "\n",
    "#use one fdra sample data to calibrate another fdra stations\n",
    "def use_another():\n",
    "    gdf_select_fuels = gdf_fdra.loc[gdf_fdra.key == 'CentralOregon_Monument']\n",
    "    gdf_select_stations = gdf_fdra.loc[gdf_fdra.key == 'WarmSprings_FMZ2']\n",
    "    \n",
    "    analysis_data_stations = GsiAnalysisData(gdf_select_stations, analysis_data_all)\n",
    "    analysis_data_stations.clip_data()\n",
    "    analysis_data_stations.prep_data()\n",
    "    analysis_data_stations.get_wx()\n",
    "    \n",
    "    analysis_data_stations.sites = None\n",
    "    analysis_data_stations.samples_herb = None\n",
    "    analysis_data_stations.samples_shrub = None\n",
    "    analysis_data_stations.samples_herb_group = None\n",
    "    analysis_data_stations.samples_shrub_group = None\n",
    "    \n",
    "    analysis_data_fuels = GsiAnalysisData(gdf_select_fuels, analysis_data_all)\n",
    "    analysis_data_fuels.clip_data()\n",
    "    analysis_data_fuels.prep_data()\n",
    "    \n",
    "    analysis_data_stations.sites = analysis_data_fuels.sites\n",
    "    analysis_data_stations.prep_data()\n",
    "    res = calibrate_gsi(analysis_data_stations, woody_or_herb)\n",
    "use_another()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a90540-db87-4c03-9f6e-63334ed5b7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
